<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=hugo-theme content="Axiom 0.8.0"><link rel=icon type=image/png sizes=32x32 href=/blog/image/brand/favicon.png><link rel=icon type=image/x-icon href=/blog/favicon.ico><link rel=apple-touch-icon href=/blog/image/brand/icon-1-1.png><link rel=canonical href=https://keithyipkw.github.io/blog/no_skip_smm_part_2/><link rel=preload as=style href="/blog/bundle.css?v=1662038494" media=all><link rel=stylesheet href="/blog/bundle.css?v=1662038494" media=all><style>.cdata pre{background-color:#1f2937;color:#e5e7eb}.cdata :not(pre)>code{background-color:#f3f4f6;color:#7c3aed}.chroma .err{background-color:#991b1b;color:#fecaca}.chroma .hl{background-color:#374151}.chroma .ln{color:#9ca3af}.chroma .k,.chroma .kc,.chroma .kd,.chroma .kn,.chroma .kp,.chroma .kr{color:#60a5fa}.chroma .kt{color:#a78bfa}.chroma .na,.chroma .nb{color:#fbbf24}.chroma .nc{color:#f87171}.chroma .no{color:#34d399}.chroma .nd{color:#f87171}.chroma .ne{color:#f87171}.chroma .nf{color:#fbbf24}.chroma .nt{color:#f87171}.chroma .l{color:#a78bfa}.chroma .dl,.chroma .ld,.chroma .s,.chroma .s2,.chroma .sa,.chroma .sb,.chroma .sc,.chroma .sd{color:#34d399}.chroma .se{color:#9ca3af}.chroma .s1,.chroma .sh,.chroma .si,.chroma .sr,.chroma .ss,.chroma .sx{color:#34d399}.chroma .il,.chroma .m,.chroma .mb,.chroma .mf,.chroma .mh,.chroma .mi,.chroma .mo{color:#a78bfa}.chroma .o,.chroma .ow{color:#93c5fd}.chroma .c,.chroma .c1,.chroma .ch,.chroma .cm,.chroma .cp,.chroma .cpf,.chroma .cs,.chroma .p{color:#9ca3af}.chroma .ge{font-style:italic}.chroma .gs{font-weight:700}</style><title>Endless Expert Levels Without Skipping in SMM2 - Part 2 - STEM</title><meta property="og:title" content="Endless Expert Levels Without Skipping in SMM2 - Part 2"><meta property="og:site_name" content="STEM"><meta property="og:url" content="https://keithyipkw.github.io/blog/no_skip_smm_part_2/"><link rel=image_src href=https://keithyipkw.github.io/blog/><meta property="og:image" content="https://keithyipkw.github.io/blog/"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="og:type" content="article"><meta property="og:locale" content="en_us"><meta property="og:description" content="In part 1, we learned how to use bootstraps to calculate confidence intervals of Panga's success rates of beating the various numbers of levels without skipping. We threw away the censored samples that were 31% of the samples for simplicity. This time, we will use all of them to infer the success rates and confidence intervals."><meta name=description content="In part 1, we learned how to use bootstraps to calculate confidence intervals of Panga's success rates of beating the various numbers of levels without skipping. We threw away the censored samples that were 31% of the samples for simplicity. This time, we will use all of them to infer the success rates and confidence intervals."><meta property="og:updated_time" content="2022-08-23T13:45:00Z"><meta property="fb:app_id" content><meta name=author content="Keith Yip"><meta property="article:author" content="https://keithyipkw.github.io/blog/"><meta property="article:published_time" content="2022-03-14T14:20:00Z"><meta property="article:modified_time" content="2022-08-23T13:45:00Z"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Endless Expert Levels Without Skipping in SMM2 - Part 2","alternativeHeadline":"In part 1, we learned how to use bootstraps to calculate confidence intervals of Panga's success rates of beating the various numbers of levels without skipping. We threw away the censored samples that were 31% of the samples for simplicity. This time, we will use all of them to infer the success rates and confidence intervals.","url":"https://keithyipkw.github.io/blog/no_skip_smm_part_2/","image":"https://keithyipkw.github.io/blog/","mainEntityOfPage":{"@type":"WebPage","@id":"https://keithyipkw.github.io/blog/no_skip_smm_part_2/"},"description":"In part 1, we learned how to use bootstraps to calculate confidence intervals of Panga's success rates of beating the various numbers of levels without skipping. We threw away the censored samples that were 31% of the samples for simplicity. This time, we will use all of them to infer the success rates and confidence intervals.","author":{"@type":"Person","name":"Keith Yip"},"publisher":{"@type":"Organization","name":"STEM","logo":{"@type":"ImageObject","url":"https://keithyipkw.github.io/blog/image/brand/icon-1-1.png"}},"datePublished":"2022-03-14T14:20:00Z","dateModified":"2022-08-23T13:45:00Z","articleBody":"\u003cp\u003eIn \u003ca href=\"https://keithyipkw.github.io/blog/no_skip_smm/\"\u003epart 1\u003c/a\u003e, we learned how to use bootstraps to calculate confidence intervals of Panga's success rates of beating the various numbers of levels without skipping. We threw away the censored samples that were 31% of the samples for simplicity. This time, we will use all of them to infer the success rates and confidence intervals.\u003c/p\u003e\n\u003ch1 id=\"a-better-estimator\"\u003eA Better Estimator\u003c/h1\u003e\n\u003cp\u003eThe maximum number of lives, 99, limits the maximum life change after beating a level in addition to the maximum 3-life gain. For a player having a starting life from 1 to 96 before playing a level, there is no censorship in the observation of their life change after beating the level. However, if they have a starting life from 97 to 99, the observed life change is capped. When mixing these samples with the former samples, we need to take care of this \u003ca href=\"https://en.wikipedia.org/wiki/Censoring_(statistics)\"\u003eright censoring\u003c/a\u003e problem.\u003c/p\u003e\n\u003cp\u003eThe \u003ca href=\"https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator\"\u003eKaplan–Meier estimator\u003c/a\u003e is our solution. We will group the probabilities of life changes that the censoring does not skew the estimation. By applying the same technique to each group containing multiple life changes and ignoring the censored samples useless to the subgroups, we will be able to estimate the probabilities of each subgroup. Repeating the steps will eventually give us the probabilities of each life change.\u003c/p\u003e\n\u003cp\u003eBecause we are dealing with a right censoring, we will estimate the probabilities from the most life loss toward the most life gain. For life losses, we will simply count the proportion for each one and group the remaining for life gain greater than or equal to 0. Doing so will allow us to include the censored samples when estimating the probabilities of each group. After throwing away the samples with 99 starting lives and negative life changes, we will count the proportion for 0-life change and group the remaining for 1 or more life gain. The overall proportion for 0-life change will be the product of the previous proportion for 0 or more life gain and the current proportion for 0-life change. By repeating a similar procedure for 1 to 3-life gains, we will get the probabilities for all life changes using all the samples.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/estimator_example_1a.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/estimator_example_1a.png 1x,/blog/image/no_skip_smm_2/estimator_example_1a_2x.png 2x\"\r\nalt=\"For example, a player having 97 starting lives gained 1 life once and 2 lives 6 times. In part 1, we threw away these censored samples and only relied on the samples with 1 to 96 starting lives.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eFor example, a player having 97 starting lives gained 1 life once and 2 lives 6 times. In part 1, we threw away these censored samples and only relied on the samples with 1 to 96 starting lives.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/estimator_example_1d.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/estimator_example_1d.png 1x,/blog/image/no_skip_smm_2/estimator_example_1d_2x.png 2x\"\r\nalt=\"To calculate the probability of 1-life gain, we group the samples into 1-life gain and other life gains. It is the former divided by the sum of both, which is $ \\frac{1 \u0026#43; 2}{1 \u0026#43; 2 \u0026#43; 3 \u0026#43; 6 \u0026#43; 2} = 21\\%$. That of 2 or more life gain is $ 100\\% - 21\\% = 79\\% $\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eTo calculate the probability of 1-life gain, we group the samples into 1-life gain and other life gains. It is the former divided by the sum of both, which is $ \\frac{1 + 2}{1 + 2 + 3 + 6 + 2} = 21\\%$. That of 2 or more life gain is $ 100\\% - 21\\% = 79\\% $\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/estimator_example_1e.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/estimator_example_1e.png 1x,/blog/image/no_skip_smm_2/estimator_example_1e_2x.png 2x\"\r\nalt=\"Then we throw away the samples with 97 start lives and 1-life gain. The probabilty of 2-life gain is $ \\frac{3}{3 \u0026#43; 5} \\times 79\\% = 30\\% $. That of 3-life gain is $ 79\\% - 30\\% = 49\\% $.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThen we throw away the samples with 97 start lives and 1-life gain. The probabilty of 2-life gain is $ \\frac{3}{3 + 5} \\times 79\\% = 30\\% $. That of 3-life gain is $ 79\\% - 30\\% = 49\\% $.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eFormally, let\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$ \\textcolor{red}{♥} \\in \\set{0,1,2,\\ldots,99} $ be the number of starting lives.\u003c/li\u003e\n\u003cli\u003e$ \\Delta\\textcolor{red}{♥} \\in \\set{-99, -98, -97, \\ldots, 3} $ be the life change.\u003c/li\u003e\n\u003cli\u003e$ X(c) $ be the number of samples that condition $ c $ is true.\u003c/li\u003e\n\u003cli\u003e$ P(\\Delta\\textcolor{red}{♥}) $ be the probability of life change of $ \\Delta\\textcolor{red}{♥} $ without considering the censoring.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe probabilities of negative life changes, $ m $, are:\u003c/p\u003e\n\r\n$$\r\n\\begin{aligned}\r\nP(\\Delta\\textcolor{red}{♥}=m) \u0026= \\frac{X(1\\le\\textcolor{red}{♥}\\le99,\\Delta\\textcolor{red}{♥}=m)}{X(1\\le\\textcolor{red}{♥}\\le99,-99\\le\\Delta\\textcolor{red}{♥}\\le3)}, \u0026 -99 \\le m \u003c 0\r\n\\end{aligned}\r\n$$\r\n\n\u003cp\u003eThe probability of all non-negative life changes is the complement:\u003c/p\u003e\n\r\n$$\r\nP(\\Delta\\textcolor{red}{♥}\\ge 0) = 1 - P(\\Delta\\textcolor{red}{♥}\u003c0)\r\n$$\r\n\n\u003cp\u003eThe probability of 0-life change is:\u003c/p\u003e\n\r\n$$\r\nP(\\Delta\\textcolor{red}{♥}=0) = P(\\Delta\\textcolor{red}{♥}\\ge 0) \\frac{X(1\\le\\textcolor{red}{♥}\\le98,\\Delta\\textcolor{red}{♥}=0)}{X(1\\le\\textcolor{red}{♥}\\le98,0\\le\\Delta\\textcolor{red}{♥}\\le3)} \r\n$$\r\n\n\u003cp\u003eThe probability of 1 or more life changes is:\u003c/p\u003e\n\r\n$$\r\n\r\nP(\\Delta\\textcolor{red}{♥}\\ge 1) = P(\\Delta\\textcolor{red}{♥}\\ge0) - P(\\Delta\\textcolor{red}{♥}=0)\r\n\r\n$$\r\n\n\u003cp\u003eRepeating the same logic gives the remaining probabilities:\u003c/p\u003e\n\r\n$$\r\n\\begin{aligned}\r\n\r\nP(\\Delta\\textcolor{red}{♥}\\ge 1) \u0026= P(\\Delta\\textcolor{red}{♥}\\ge0) - P(\\Delta\\textcolor{red}{♥}=0) \\\\\r\n\r\nP(\\Delta\\textcolor{red}{♥}=1) \u0026= P(\\Delta\\textcolor{red}{♥}\\ge 1) \\frac{X(1\\le\\textcolor{red}{♥}\\le97,\\Delta\\textcolor{red}{♥}=1)}{X(1\\le\\textcolor{red}{♥}\\le97,1\\le\\Delta\\textcolor{red}{♥}\\le3)} \\\\\r\n\r\nP(\\Delta\\textcolor{red}{♥}\\ge 2) \u0026= P(\\Delta\\textcolor{red}{♥}\\ge1) - P(\\Delta\\textcolor{red}{♥}=1) \\\\\r\n\r\nP(\\Delta\\textcolor{red}{♥}=2) \u0026= P(\\Delta\\textcolor{red}{♥}\\ge 2) \\frac{X(1\\le\\textcolor{red}{♥}\\le96,\\Delta\\textcolor{red}{♥}=2)}{X(1\\le\\textcolor{red}{♥}\\le96,2\\le\\Delta\\textcolor{red}{♥}\\le3)} \\\\\r\n\r\nP(\\Delta\\textcolor{red}{♥}=3) \u0026= P(\\Delta\\textcolor{red}{♥}\\ge2) - P(\\Delta\\textcolor{red}{♥}=2) \\\\\r\n\r\n\\end{aligned}\r\n$$\r\n\n\u003ch1 id=\"sampling-process\"\u003eSampling Process\u003c/h1\u003e\n\u003cp\u003eThe sampling process is different from independently drawing samples from a distribution with replacements that non-parametric bootstraps work perfectly. The censoring of a sample depends on the starting life where the life is the sum of the starting lives and the life change of its predecessor. The probabilities of life changes correlate with the censoring. The better the player is, the heavier the censoring there is. It is not obvious if a simple non-parametric bootstrap will work. Instead, we use parametric bootstraps with a model of the sampling process to calculate the confidence intervals.\u003c/p\u003e\n\u003cp\u003eLike the non-parametric counterparts, the BCa version is the least restrictive and generally provides the most accurate confidence intervals. However, it is more complicated than the non-parametric counterpart, especially when dealing with correlated samples. The details can be found in section 4 of \u003cem\u003eThe Automatic Construction of Bootstrap Confidence Intervals\u003c/em\u003e by Bradley Efron and Balasubramanian Narasimhan\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\u003cp\u003eRather than jumping into another deep rabbit hole immediately, we will spend some time studying the problem first by examining the actual differences between the samples obtained by different sampling processes. Below are some simulations of the original sampling, a multinomial sampling, and a non-parametric resampling process. Including the resampling process will help us to decide if a BCa bootstrap is necessary. There were 1058 samples of levels from part 1. The life change probabilities given by the Kaplan-Meier estimator formed a multinomial distribution. It was the basis of the simulations for the original sampling and multinomial sampling.\u003c/p\u003e\n\u003cp\u003eThe original sampling process drew a sequence of 1058 levels from the distribution with replacements. It assigned 15 starting lives to the first level. The starting lives for each successive level were the sum of the current start lives and the life change. They were less than or equal to 99. Whenever a starting life fell below 1, it became 15 as if a run restarted. The Kaplan–Meier estimator gave an estimate of the life change probabilities for a new set of samples. In the simulation, I repeated the process 1,000,000 times and obtained distributions of the simulated estimates.\u003c/p\u003e\n\u003cp\u003eIn the multinomial sampling, drawing 1058 levels was the whole process. There was no censoring. The process was simple enough that a formula for the exact distributions existed. I did not have to run a simulation.\u003c/p\u003e\n\u003cp\u003eThe resampling was the same as those in non-parametric bootstraps. It directly drew new sets of 1058 samples from the 1058 samples with replacements. Like the other simulation, I repeated it 1,000,000 times and obtained the corresponding distributions again.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/life_change_pmf.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/life_change_pmf.png 1x,/blog/image/no_skip_smm_2/life_change_pmf_2x.png 2x\"\r\nalt=\"The probabilties of Panga\u0026#39;s life change after beating a level estimated by the Kaplan–Meier estimator.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe probabilties of Panga's life change after beating a level estimated by the Kaplan–Meier estimator.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/-1_life_gain_cdf.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/-1_life_gain_cdf.png 1x,/blog/image/no_skip_smm_2/-1_life_gain_cdf_2x.png 2x\"\r\nalt=\"The cumulative distributions of the probabilities of 1 life loss by the simulated sampling processes. The censoring did not affect life loss, so the distributions were the same.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe cumulative distributions of the probabilities of 1 life loss by the simulated sampling processes. The censoring did not affect life loss, so the distributions were the same.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/3_life_gain_cdf.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/3_life_gain_cdf.png 1x,/blog/image/no_skip_smm_2/3_life_gain_cdf_2x.png 2x\"\r\nalt=\"The cumulative distributions of the probabilities of 3-life gain by the simulated sampling processes. That by the original sampling and the resampling were very close, unlike the multinomial sampling.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe cumulative distributions of the probabilities of 3-life gain by the simulated sampling processes. That by the original sampling and the resampling were very close, unlike the multinomial sampling.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eThe distributions of the probabilities of the non-negative life changes calculated by the original sampling process and the resamplings were considerably close. You would probably guess that the distributions of the sample success rates would behave the same. Simulating 400,000 times gave the following results. That by the resampling was indeed very close to that by the original sampling, but that by the multinomial sampling was even closer. Using only certain numbers of initial samples, e.g., 25% or 50%, gave similar results. A rigorous proof should cover all distributions of life change probabilities, but for now, let us assume that all sampling processes are practically the same.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/beat_1000_cdf.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/beat_1000_cdf.png 1x,/blog/image/no_skip_smm_2/beat_1000_cdf_2x.png 2x\"\r\nalt=\"The cumulative distributions of the success rates of beating 1000 levels. The line for the original sample was behind that for the multinomial sampling. All were very close. There was only a small bias in that by the resampling.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe cumulative distributions of the success rates of beating 1000 levels. The line for the original sample was behind that for the multinomial sampling. All were very close. There was only a small bias in that by the resampling.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/beat_1000_cdf_zoom.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/beat_1000_cdf_zoom.png 1x,/blog/image/no_skip_smm_2/beat_1000_cdf_zoom_2x.png 2x\"\r\nalt=\"A zoomed section of the previous graph. The distributions by the original sampling and the multinomial sampling were virtually indistinguishable. That by the resampling was slightly different but still practically the same.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eA zoomed section of the previous graph. The distributions by the original sampling and the multinomial sampling were virtually indistinguishable. That by the resampling was slightly different but still practically the same.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003ch1 id=\"bootstrap-method\"\u003eBootstrap Method\u003c/h1\u003e\n\u003cp\u003eIf you pay close attention to the result in part 1, you will notice that the confidence limits were weird. The upper confidence limits were non-sensible after 1200 levels. They rose slightly after 1200 levels. The state of a run can never transit from ended to in-progress, so the success rates must be monotonic decreasing. A similar logic applies to the bootstrap replications of the success rates too. The distribution of the bootstrap replications is an ordered set of success rates. Although the success rates for different life change probabilities may reorder in the next number of levels, an element in an ordered set of the success rates are monotonic decreasing. The lower confidence limits plateaued between 1200 to 1500 levels. It probably traced back to a sudden increment of around 750 levels suggested by the coverage simulation. The randomness in the bootstrap did not cause the weirdness. We used a large enough number of bootstrap replications that the confidence limits converged. Running the bootstrap with different random seeds would give the same result. These issues happened because we used the BCa bootstrap to calculate with extreme confidence limits. The BCa bootstrap was unstable when the confidence intervals were larger than 95%\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/part1_pangas_probabilities_simplified.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/part1_pangas_probabilities_simplified.png 1x,/blog/image/no_skip_smm_2/part1_pangas_probabilities_simplified_2x.png 2x\"\r\nalt=\"The confidence limits from part 1. The upper confidence limits rose after 1200 levels while the lower confidence limits plateaued between 1200 to 1500 levels.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe confidence limits from part 1. The upper confidence limits rose after 1200 levels while the lower confidence limits plateaued between 1200 to 1500 levels.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eThis time we check the results of different bootstrap methods instead of blindly going with a BCa bootstrap. I calculated the confidence limits of the success rates of beating 1 to 3000 levels, the cumulative distribution functions of the success rates of beating 1000 levels calculated by the three bootstrap methods with 400,000 resamples, and a simulation study of the coverages of the confidence intervals. Below is the results:\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/bootstrap_method_comparision.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/bootstrap_method_comparision.png 1x,/blog/image/no_skip_smm_2/bootstrap_method_comparision_2x.png 2x\"\r\nalt=\"The confidence intervals calculated by the three bootstrap methods.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe confidence intervals calculated by the three bootstrap methods.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/bootstrap_method_comparision_1000.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/bootstrap_method_comparision_1000.png 1x,/blog/image/no_skip_smm_2/bootstrap_method_comparision_1000_2x.png 2x\"\r\nalt=\"The cumulative distributions of the success rate of beating 1000 levels calculated by the three bootstrap methods.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe cumulative distributions of the success rate of beating 1000 levels calculated by the three bootstrap methods.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/bootstrap_ci_0.95.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/bootstrap_ci_0.95.png 1x,/blog/image/no_skip_smm_2/bootstrap_ci_0.95_2x.png 2x\"\r\nalt=\"The coverages of 95% confidence intervals by 4000 simulations.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe coverages of 95% confidence intervals by 4000 simulations.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/bootstrap_ci_0.99.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/bootstrap_ci_0.99.png 1x,/blog/image/no_skip_smm_2/bootstrap_ci_0.99_2x.png 2x\"\r\nalt=\"The coverages of 99% confidence intervals by 4000 simulations.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe coverages of 99% confidence intervals by 4000 simulations.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eThe same issue showed up again. In comparison, the BC bootstrap performed better than the BCa bootstrap. It gave similar results most of the time but without instability. Combining it with the result from the previous section that the non-parametric resampling process approximated the original sampling process well, we can conclude that the parametric BC bootstrap is the way to go. We have just come full circle.\u003c/p\u003e\n\u003ch1 id=\"result\"\u003eResult\u003c/h1\u003e\n\u003cp\u003ePanga did better in this larger set of samples than the subset in part 1. He gained 0.287 lives on average after beating a level. Below is the results. As a reminder, the inference used here is frequentist. The probabilities of the confidence intervals and cumulative probability refer to the corresponding (hypothetical) long-run frequencies of those being true for the same sampling and estimation procedure.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eLevels\u003c/th\u003e\n\u003cth\u003eProbability\u003c/th\u003e\n\u003cth\u003e95% CI\u003c/th\u003e\n\u003cth\u003e99% CI\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e1000\u003c/td\u003e\n\u003ctd\u003e71.2%\u003c/td\u003e\n\u003ctd\u003e[36.7%, 88.1%]\u003c/td\u003e\n\u003ctd\u003e[24.7%, 91.3%]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2000\u003c/td\u003e\n\u003ctd\u003e70%\u003c/td\u003e\n\u003ctd\u003e[27.6%, 88.1%]\u003c/td\u003e\n\u003ctd\u003e[14.4%, 91.3%]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3000\u003c/td\u003e\n\u003ctd\u003e68.8%\u003c/td\u003e\n\u003ctd\u003e[20.7%, 88%]\u003c/td\u003e\n\u003ctd\u003e[8.41%, 91.3%]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/pangas_probabilities.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/pangas_probabilities.png 1x,/blog/image/no_skip_smm_2/pangas_probabilities_2x.png 2x\"\r\nalt=\"Probabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eProbabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/pangas_probabilities_simplified.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/pangas_probabilities_simplified.png 1x,/blog/image/no_skip_smm_2/pangas_probabilities_simplified_2x.png 2x\"\r\nalt=\"Probabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eProbabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/pangas_probability_1000.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/pangas_probability_1000.png 1x,/blog/image/no_skip_smm_2/pangas_probability_1000_2x.png 2x\"\r\nalt=\"Probability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eProbability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_2/pangas_cdf_1000.png\"\r\nsrcset=\"/blog/image/no_skip_smm_2/pangas_cdf_1000.png 1x,/blog/image/no_skip_smm_2/pangas_cdf_1000_2x.png 2x\"\r\nalt=\"Cumulative probability of Panga successfully beating 1000 levels.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eCumulative probability of Panga successfully beating 1000 levels.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eCompared to the result in part 1, the sample probabilities of beating 1000, 2000, and 3000 levels are 10% more. The upper confidence limits stay approximately the same while the bottom confidence limits shift upwards substantially. While most players struggle to beat 10 levels, Panga, being one of the best players in Super Mario Maker, only needs a few trials to have a decent chance to beat 1000 levels or even 2000 levels.\u003c/p\u003e\n\u003ch1 id=\"conclusion\"\u003eConclusion\u003c/h1\u003e\n\u003cp\u003eThis time we have squeezed all information out of our precious samples. As of the time I am writing this, Panga's best run had already passed 1000 levels, ended at 1906 levels\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e. He is devoted to reaching 2000 levels. It means that we have more samples to reduce the uncertainty in our estimations. Besides, there are other interesting things to discuss in the \u003ca href=\"https://keithyipkw.github.io/blog/no_skip_smm_part_3/\"\u003epart 3\u003c/a\u003e.\u003c/p\u003e\n\u003csection class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n\u003cp\u003eBradley Efron \u0026amp; Balasubramanian Narasimhan (2020) The Automatic Construction of Bootstrap Confidence Intervals, Journal of Computational and Graphical Statistics, 29:3, 608-619, DOI: 10.1080/10618600.2020.1714633 \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n\u003cp\u003eCarpenter, J. and Bithell, J. (2000), Bootstrap confidence intervals: when, which, what? A practical guide for medical statisticians. Statist. Med., 19: 1141-1164. \u003ca href=\"https://doi.org/10.1002/(SICI)1097-0258(20000515)19:9\"\u003ehttps://doi.org/10.1002/(SICI)1097-0258(20000515)19:9\u003c/a\u003e\u0026lt;1141::AID-SIM479\u0026gt;3.0.CO;2-F \u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\" role=\"doc-endnote\"\u003e\n\u003cp\u003ePangaeaPanga, This Run Got to ONE LIFE — Clearing 2000 EXPERT Levels (No-Skips) | S2 EP78 \u003ca href=\"https://youtu.be/hvbGMohca94?t=1070\"\u003ehttps://youtu.be/hvbGMohca94?t=1070\u003c/a\u003e \u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/section\u003e"}</script><link rel=preload as=script href="/blog/bundle.js?v=1662038494"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://stats.g.doubleclick.net><link rel=preconnect href=https://www.googleadservices.com><link rel=preload as=script href="https://www.googletagmanager.com/gtag/js?id=G-5Y5GJS2SYG"><script src="https://www.googletagmanager.com/gtag/js?id=G-5Y5GJS2SYG"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('consent','default',{'ad_storage':'denied','analytics_storage':'denied'});gtag('js',new Date());gtag('config','G-5Y5GJS2SYG');</script><meta name=twitter:card content="summary"><meta name=twitter:title content="Endless Expert Levels Without Skipping in SMM2 - Part 2"><meta name=twitter:description content="In part 1, we learned how to use bootstraps to calculate confidence intervals of Panga's success rates of beating the various numbers of levels without skipping. We threw away the censored samples that were 31% of the samples for simplicity. This time, we will use all of them to infer the success rates and confidence intervals."><script>MathJax={loader:{load:['[tex]/mathtools']},tex:{inlineMath:[['$','$']],packages:{'[+]':['mathtools']},tags:'ams'}};</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><header id=nav class=header><div class="ax-l-i max-w-7xl"><div class=ax-logo><a class=block href=/blog/ title=STEM><img src=/blog/image/brand/logo.png alt=STEM></a></div><div class=ax-user></div></div></header><main><div class=default-single><div class="ax-title ax-l-o"><div class="ax-l-i max-w-7xl"><h1 class="post-title font-content-title font-semibold leading-tight tracking-default text-40">Endless Expert Levels Without Skipping in SMM2 - Part 2</h1><div class="ax-meta flex items-center mt-5"><div class="flex-grow min-w-0"><div class="flex items-center"><div class="flex-shrink-0 leading-tight font-content-sans"><div class="block text-sm">Keith Yip</div><time class="text-sm text-raven-500" datetime=2022-03-14T14:20:00Z>Mar 14, 2022 10:20PM</time><div class="text-sm text-raven-500">Updated at
<time class="text-sm text-raven-500" datetime=2022-03-14T14:20:00Z>Aug 23, 2022 9:45PM</time></div></div></div></div></div></div></div><div class="flex flex-wrap justify-center"><a class="rounded font-content-sans font-semibold text-raven-700 bg-raven-100 hover:bg-raven-200 py-2 px-4 m-2" href=https://keithyipkw.github.io/blog/tags/statistics/>Statistics</a></div><div class="ax-content ax-l-o"><div class="ax-l-i max-w-7xl"><article class=cdata><p>In <a href=https://keithyipkw.github.io/blog/no_skip_smm/>part 1</a>, we learned how to use bootstraps to calculate confidence intervals of Panga's success rates of beating the various numbers of levels without skipping. We threw away the censored samples that were 31% of the samples for simplicity. This time, we will use all of them to infer the success rates and confidence intervals.</p><h1 id=a-better-estimator>A Better Estimator</h1><p>The maximum number of lives, 99, limits the maximum life change after beating a level in addition to the maximum 3-life gain. For a player having a starting life from 1 to 96 before playing a level, there is no censorship in the observation of their life change after beating the level. However, if they have a starting life from 97 to 99, the observed life change is capped. When mixing these samples with the former samples, we need to take care of this <a href=https://en.wikipedia.org/wiki/Censoring_(statistics)>right censoring</a> problem.</p><p>The <a href=https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator>Kaplan–Meier estimator</a> is our solution. We will group the probabilities of life changes that the censoring does not skew the estimation. By applying the same technique to each group containing multiple life changes and ignoring the censored samples useless to the subgroups, we will be able to estimate the probabilities of each subgroup. Repeating the steps will eventually give us the probabilities of each life change.</p><p>Because we are dealing with a right censoring, we will estimate the probabilities from the most life loss toward the most life gain. For life losses, we will simply count the proportion for each one and group the remaining for life gain greater than or equal to 0. Doing so will allow us to include the censored samples when estimating the probabilities of each group. After throwing away the samples with 99 starting lives and negative life changes, we will count the proportion for 0-life change and group the remaining for 1 or more life gain. The overall proportion for 0-life change will be the product of the previous proportion for 0 or more life gain and the current proportion for 0-life change. By repeating a similar procedure for 1 to 3-life gains, we will get the probabilities for all life changes using all the samples.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/estimator_example_1a.png srcset="/blog/image/no_skip_smm_2/estimator_example_1a.png 1x,/blog/image/no_skip_smm_2/estimator_example_1a_2x.png 2x" alt="For example, a player having 97 starting lives gained 1 life once and 2 lives 6 times. In part 1, we threw away these censored samples and only relied on the samples with 1 to 96 starting lives."><figcaption class="text-center text-raven-500"><p>For example, a player having 97 starting lives gained 1 life once and 2 lives 6 times. In part 1, we threw away these censored samples and only relied on the samples with 1 to 96 starting lives.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/estimator_example_1d.png srcset="/blog/image/no_skip_smm_2/estimator_example_1d.png 1x,/blog/image/no_skip_smm_2/estimator_example_1d_2x.png 2x" alt="To calculate the probability of 1-life gain, we group the samples into 1-life gain and other life gains. It is the former divided by the sum of both, which is $ \frac{1 + 2}{1 + 2 + 3 + 6 + 2} = 21\%$. That of 2 or more life gain is $ 100\% - 21\% = 79\% $"><figcaption class="text-center text-raven-500"><p>To calculate the probability of 1-life gain, we group the samples into 1-life gain and other life gains. It is the former divided by the sum of both, which is $ \frac{1 + 2}{1 + 2 + 3 + 6 + 2} = 21\%$. That of 2 or more life gain is $ 100\% - 21\% = 79\% $</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/estimator_example_1e.png srcset="/blog/image/no_skip_smm_2/estimator_example_1e.png 1x,/blog/image/no_skip_smm_2/estimator_example_1e_2x.png 2x" alt="Then we throw away the samples with 97 start lives and 1-life gain. The probabilty of 2-life gain is $ \frac{3}{3 + 5} \times 79\% = 30\% $. That of 3-life gain is $ 79\% - 30\% = 49\% $."><figcaption class="text-center text-raven-500"><p>Then we throw away the samples with 97 start lives and 1-life gain. The probabilty of 2-life gain is $ \frac{3}{3 + 5} \times 79\% = 30\% $. That of 3-life gain is $ 79\% - 30\% = 49\% $.</p></figcaption></figure><p>Formally, let</p><ul><li>$ \textcolor{red}{♥} \in \set{0,1,2,\ldots,99} $ be the number of starting lives.</li><li>$ \Delta\textcolor{red}{♥} \in \set{-99, -98, -97, \ldots, 3} $ be the life change.</li><li>$ X(c) $ be the number of samples that condition $ c $ is true.</li><li>$ P(\Delta\textcolor{red}{♥}) $ be the probability of life change of $ \Delta\textcolor{red}{♥} $ without considering the censoring.</li></ul><p>The probabilities of negative life changes, $ m $, are:</p>$$
\begin{aligned}
P(\Delta\textcolor{red}{♥}=m) &= \frac{X(1\le\textcolor{red}{♥}\le99,\Delta\textcolor{red}{♥}=m)}{X(1\le\textcolor{red}{♥}\le99,-99\le\Delta\textcolor{red}{♥}\le3)}, & -99 \le m < 0
\end{aligned}
$$<p>The probability of all non-negative life changes is the complement:</p>$$
P(\Delta\textcolor{red}{♥}\ge 0) = 1 - P(\Delta\textcolor{red}{♥}<0)
$$<p>The probability of 0-life change is:</p>$$
P(\Delta\textcolor{red}{♥}=0) = P(\Delta\textcolor{red}{♥}\ge 0) \frac{X(1\le\textcolor{red}{♥}\le98,\Delta\textcolor{red}{♥}=0)}{X(1\le\textcolor{red}{♥}\le98,0\le\Delta\textcolor{red}{♥}\le3)}
$$<p>The probability of 1 or more life changes is:</p>$$
P(\Delta\textcolor{red}{♥}\ge 1) = P(\Delta\textcolor{red}{♥}\ge0) - P(\Delta\textcolor{red}{♥}=0)
$$<p>Repeating the same logic gives the remaining probabilities:</p>$$
\begin{aligned}
P(\Delta\textcolor{red}{♥}\ge 1) &= P(\Delta\textcolor{red}{♥}\ge0) - P(\Delta\textcolor{red}{♥}=0) \\
P(\Delta\textcolor{red}{♥}=1) &= P(\Delta\textcolor{red}{♥}\ge 1) \frac{X(1\le\textcolor{red}{♥}\le97,\Delta\textcolor{red}{♥}=1)}{X(1\le\textcolor{red}{♥}\le97,1\le\Delta\textcolor{red}{♥}\le3)} \\
P(\Delta\textcolor{red}{♥}\ge 2) &= P(\Delta\textcolor{red}{♥}\ge1) - P(\Delta\textcolor{red}{♥}=1) \\
P(\Delta\textcolor{red}{♥}=2) &= P(\Delta\textcolor{red}{♥}\ge 2) \frac{X(1\le\textcolor{red}{♥}\le96,\Delta\textcolor{red}{♥}=2)}{X(1\le\textcolor{red}{♥}\le96,2\le\Delta\textcolor{red}{♥}\le3)} \\
P(\Delta\textcolor{red}{♥}=3) &= P(\Delta\textcolor{red}{♥}\ge2) - P(\Delta\textcolor{red}{♥}=2) \\
\end{aligned}
$$<h1 id=sampling-process>Sampling Process</h1><p>The sampling process is different from independently drawing samples from a distribution with replacements that non-parametric bootstraps work perfectly. The censoring of a sample depends on the starting life where the life is the sum of the starting lives and the life change of its predecessor. The probabilities of life changes correlate with the censoring. The better the player is, the heavier the censoring there is. It is not obvious if a simple non-parametric bootstrap will work. Instead, we use parametric bootstraps with a model of the sampling process to calculate the confidence intervals.</p><p>Like the non-parametric counterparts, the BCa version is the least restrictive and generally provides the most accurate confidence intervals. However, it is more complicated than the non-parametric counterpart, especially when dealing with correlated samples. The details can be found in section 4 of <em>The Automatic Construction of Bootstrap Confidence Intervals</em> by Bradley Efron and Balasubramanian Narasimhan<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>Rather than jumping into another deep rabbit hole immediately, we will spend some time studying the problem first by examining the actual differences between the samples obtained by different sampling processes. Below are some simulations of the original sampling, a multinomial sampling, and a non-parametric resampling process. Including the resampling process will help us to decide if a BCa bootstrap is necessary. There were 1058 samples of levels from part 1. The life change probabilities given by the Kaplan-Meier estimator formed a multinomial distribution. It was the basis of the simulations for the original sampling and multinomial sampling.</p><p>The original sampling process drew a sequence of 1058 levels from the distribution with replacements. It assigned 15 starting lives to the first level. The starting lives for each successive level were the sum of the current start lives and the life change. They were less than or equal to 99. Whenever a starting life fell below 1, it became 15 as if a run restarted. The Kaplan–Meier estimator gave an estimate of the life change probabilities for a new set of samples. In the simulation, I repeated the process 1,000,000 times and obtained distributions of the simulated estimates.</p><p>In the multinomial sampling, drawing 1058 levels was the whole process. There was no censoring. The process was simple enough that a formula for the exact distributions existed. I did not have to run a simulation.</p><p>The resampling was the same as those in non-parametric bootstraps. It directly drew new sets of 1058 samples from the 1058 samples with replacements. Like the other simulation, I repeated it 1,000,000 times and obtained the corresponding distributions again.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/life_change_pmf.png srcset="/blog/image/no_skip_smm_2/life_change_pmf.png 1x,/blog/image/no_skip_smm_2/life_change_pmf_2x.png 2x" alt="The probabilties of Panga's life change after beating a level estimated by the Kaplan–Meier estimator."><figcaption class="text-center text-raven-500"><p>The probabilties of Panga's life change after beating a level estimated by the Kaplan–Meier estimator.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/-1_life_gain_cdf.png srcset="/blog/image/no_skip_smm_2/-1_life_gain_cdf.png 1x,/blog/image/no_skip_smm_2/-1_life_gain_cdf_2x.png 2x" alt="The cumulative distributions of the probabilities of 1 life loss by the simulated sampling processes. The censoring did not affect life loss, so the distributions were the same."><figcaption class="text-center text-raven-500"><p>The cumulative distributions of the probabilities of 1 life loss by the simulated sampling processes. The censoring did not affect life loss, so the distributions were the same.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/3_life_gain_cdf.png srcset="/blog/image/no_skip_smm_2/3_life_gain_cdf.png 1x,/blog/image/no_skip_smm_2/3_life_gain_cdf_2x.png 2x" alt="The cumulative distributions of the probabilities of 3-life gain by the simulated sampling processes. That by the original sampling and the resampling were very close, unlike the multinomial sampling."><figcaption class="text-center text-raven-500"><p>The cumulative distributions of the probabilities of 3-life gain by the simulated sampling processes. That by the original sampling and the resampling were very close, unlike the multinomial sampling.</p></figcaption></figure><p>The distributions of the probabilities of the non-negative life changes calculated by the original sampling process and the resamplings were considerably close. You would probably guess that the distributions of the sample success rates would behave the same. Simulating 400,000 times gave the following results. That by the resampling was indeed very close to that by the original sampling, but that by the multinomial sampling was even closer. Using only certain numbers of initial samples, e.g., 25% or 50%, gave similar results. A rigorous proof should cover all distributions of life change probabilities, but for now, let us assume that all sampling processes are practically the same.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/beat_1000_cdf.png srcset="/blog/image/no_skip_smm_2/beat_1000_cdf.png 1x,/blog/image/no_skip_smm_2/beat_1000_cdf_2x.png 2x" alt="The cumulative distributions of the success rates of beating 1000 levels. The line for the original sample was behind that for the multinomial sampling. All were very close. There was only a small bias in that by the resampling."><figcaption class="text-center text-raven-500"><p>The cumulative distributions of the success rates of beating 1000 levels. The line for the original sample was behind that for the multinomial sampling. All were very close. There was only a small bias in that by the resampling.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/beat_1000_cdf_zoom.png srcset="/blog/image/no_skip_smm_2/beat_1000_cdf_zoom.png 1x,/blog/image/no_skip_smm_2/beat_1000_cdf_zoom_2x.png 2x" alt="A zoomed section of the previous graph. The distributions by the original sampling and the multinomial sampling were virtually indistinguishable. That by the resampling was slightly different but still practically the same."><figcaption class="text-center text-raven-500"><p>A zoomed section of the previous graph. The distributions by the original sampling and the multinomial sampling were virtually indistinguishable. That by the resampling was slightly different but still practically the same.</p></figcaption></figure><h1 id=bootstrap-method>Bootstrap Method</h1><p>If you pay close attention to the result in part 1, you will notice that the confidence limits were weird. The upper confidence limits were non-sensible after 1200 levels. They rose slightly after 1200 levels. The state of a run can never transit from ended to in-progress, so the success rates must be monotonic decreasing. A similar logic applies to the bootstrap replications of the success rates too. The distribution of the bootstrap replications is an ordered set of success rates. Although the success rates for different life change probabilities may reorder in the next number of levels, an element in an ordered set of the success rates are monotonic decreasing. The lower confidence limits plateaued between 1200 to 1500 levels. It probably traced back to a sudden increment of around 750 levels suggested by the coverage simulation. The randomness in the bootstrap did not cause the weirdness. We used a large enough number of bootstrap replications that the confidence limits converged. Running the bootstrap with different random seeds would give the same result. These issues happened because we used the BCa bootstrap to calculate with extreme confidence limits. The BCa bootstrap was unstable when the confidence intervals were larger than 95%<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/part1_pangas_probabilities_simplified.png srcset="/blog/image/no_skip_smm_2/part1_pangas_probabilities_simplified.png 1x,/blog/image/no_skip_smm_2/part1_pangas_probabilities_simplified_2x.png 2x" alt="The confidence limits from part 1. The upper confidence limits rose after 1200 levels while the lower confidence limits plateaued between 1200 to 1500 levels."><figcaption class="text-center text-raven-500"><p>The confidence limits from part 1. The upper confidence limits rose after 1200 levels while the lower confidence limits plateaued between 1200 to 1500 levels.</p></figcaption></figure><p>This time we check the results of different bootstrap methods instead of blindly going with a BCa bootstrap. I calculated the confidence limits of the success rates of beating 1 to 3000 levels, the cumulative distribution functions of the success rates of beating 1000 levels calculated by the three bootstrap methods with 400,000 resamples, and a simulation study of the coverages of the confidence intervals. Below is the results:</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/bootstrap_method_comparision.png srcset="/blog/image/no_skip_smm_2/bootstrap_method_comparision.png 1x,/blog/image/no_skip_smm_2/bootstrap_method_comparision_2x.png 2x" alt="The confidence intervals calculated by the three bootstrap methods."><figcaption class="text-center text-raven-500"><p>The confidence intervals calculated by the three bootstrap methods.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/bootstrap_method_comparision_1000.png srcset="/blog/image/no_skip_smm_2/bootstrap_method_comparision_1000.png 1x,/blog/image/no_skip_smm_2/bootstrap_method_comparision_1000_2x.png 2x" alt="The cumulative distributions of the success rate of beating 1000 levels calculated by the three bootstrap methods."><figcaption class="text-center text-raven-500"><p>The cumulative distributions of the success rate of beating 1000 levels calculated by the three bootstrap methods.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/bootstrap_ci_0.95.png srcset="/blog/image/no_skip_smm_2/bootstrap_ci_0.95.png 1x,/blog/image/no_skip_smm_2/bootstrap_ci_0.95_2x.png 2x" alt="The coverages of 95% confidence intervals by 4000 simulations."><figcaption class="text-center text-raven-500"><p>The coverages of 95% confidence intervals by 4000 simulations.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/bootstrap_ci_0.99.png srcset="/blog/image/no_skip_smm_2/bootstrap_ci_0.99.png 1x,/blog/image/no_skip_smm_2/bootstrap_ci_0.99_2x.png 2x" alt="The coverages of 99% confidence intervals by 4000 simulations."><figcaption class="text-center text-raven-500"><p>The coverages of 99% confidence intervals by 4000 simulations.</p></figcaption></figure><p>The same issue showed up again. In comparison, the BC bootstrap performed better than the BCa bootstrap. It gave similar results most of the time but without instability. Combining it with the result from the previous section that the non-parametric resampling process approximated the original sampling process well, we can conclude that the parametric BC bootstrap is the way to go. We have just come full circle.</p><h1 id=result>Result</h1><p>Panga did better in this larger set of samples than the subset in part 1. He gained 0.287 lives on average after beating a level. Below is the results. As a reminder, the inference used here is frequentist. The probabilities of the confidence intervals and cumulative probability refer to the corresponding (hypothetical) long-run frequencies of those being true for the same sampling and estimation procedure.</p><table><thead><tr><th>Levels</th><th>Probability</th><th>95% CI</th><th>99% CI</th></tr></thead><tbody><tr><td>1000</td><td>71.2%</td><td>[36.7%, 88.1%]</td><td>[24.7%, 91.3%]</td></tr><tr><td>2000</td><td>70%</td><td>[27.6%, 88.1%]</td><td>[14.4%, 91.3%]</td></tr><tr><td>3000</td><td>68.8%</td><td>[20.7%, 88%]</td><td>[8.41%, 91.3%]</td></tr></tbody></table><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/pangas_probabilities.png srcset="/blog/image/no_skip_smm_2/pangas_probabilities.png 1x,/blog/image/no_skip_smm_2/pangas_probabilities_2x.png 2x" alt="Probabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities."><figcaption class="text-center text-raven-500"><p>Probabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/pangas_probabilities_simplified.png srcset="/blog/image/no_skip_smm_2/pangas_probabilities_simplified.png 1x,/blog/image/no_skip_smm_2/pangas_probabilities_simplified_2x.png 2x" alt="Probabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown."><figcaption class="text-center text-raven-500"><p>Probabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/pangas_probability_1000.png srcset="/blog/image/no_skip_smm_2/pangas_probability_1000.png 1x,/blog/image/no_skip_smm_2/pangas_probability_1000_2x.png 2x" alt="Probability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward."><figcaption class="text-center text-raven-500"><p>Probability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_2/pangas_cdf_1000.png srcset="/blog/image/no_skip_smm_2/pangas_cdf_1000.png 1x,/blog/image/no_skip_smm_2/pangas_cdf_1000_2x.png 2x" alt="Cumulative probability of Panga successfully beating 1000 levels."><figcaption class="text-center text-raven-500"><p>Cumulative probability of Panga successfully beating 1000 levels.</p></figcaption></figure><p>Compared to the result in part 1, the sample probabilities of beating 1000, 2000, and 3000 levels are 10% more. The upper confidence limits stay approximately the same while the bottom confidence limits shift upwards substantially. While most players struggle to beat 10 levels, Panga, being one of the best players in Super Mario Maker, only needs a few trials to have a decent chance to beat 1000 levels or even 2000 levels.</p><h1 id=conclusion>Conclusion</h1><p>This time we have squeezed all information out of our precious samples. As of the time I am writing this, Panga's best run had already passed 1000 levels, ended at 1906 levels<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>. He is devoted to reaching 2000 levels. It means that we have more samples to reduce the uncertainty in our estimations. Besides, there are other interesting things to discuss in the <a href=https://keithyipkw.github.io/blog/no_skip_smm_part_3/>part 3</a>.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Bradley Efron & Balasubramanian Narasimhan (2020) The Automatic Construction of Bootstrap Confidence Intervals, Journal of Computational and Graphical Statistics, 29:3, 608-619, DOI: 10.1080/10618600.2020.1714633 <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>Carpenter, J. and Bithell, J. (2000), Bootstrap confidence intervals: when, which, what? A practical guide for medical statisticians. Statist. Med., 19: 1141-1164. <a href=https://doi.org/10.1002/(SICI)1097-0258(20000515)19:9>https://doi.org/10.1002/(SICI)1097-0258(20000515)19:9</a>&lt;1141::AID-SIM479>3.0.CO;2-F <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>PangaeaPanga, This Run Got to ONE LIFE — Clearing 2000 EXPERT Levels (No-Skips) | S2 EP78 <a href="https://youtu.be/hvbGMohca94?t=1070">https://youtu.be/hvbGMohca94?t=1070</a> <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></article></div></div></div></main><footer class=footer><div class="ax-l-i max-w-6xl"><nav class="flex items-center justify-center"><a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href=/blog/about/>About</a>
<a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href=/blog/copyright/>Copyright</a></nav><div class="footer-copyright text-sm text-center text-gray-400 mt-4">&#169; 2022 STEM</div><div class="text-sm sm:text-xs text-center text-gray-400 mt-2">Powered by <a href="https://www.axiomtheme.com/?utm_source=theme-footer&utm_medium=website&utm_campaign=referral">Axiom</a></div></div></footer><script src="/blog/bundle.js?v=1662038494"></script></body></html>