<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=hugo-theme content="Axiom 0.8.0"><link rel=icon type=image/png sizes=32x32 href=/blog/image/brand/favicon.png><link rel=icon type=image/x-icon href=/blog/favicon.ico><link rel=apple-touch-icon href=/blog/image/brand/icon-1-1.png><link rel=canonical href=https://keithyipkw.github.io/blog/no_skip_smm_part_3/><link rel=preload as=style href="/blog/bundle.css?v=1661093204" media=all><link rel=stylesheet href="/blog/bundle.css?v=1661093204" media=all><style>.cdata pre{background-color:#1f2937;color:#e5e7eb}.cdata :not(pre)>code{background-color:#f3f4f6;color:#7c3aed}.chroma .err{background-color:#991b1b;color:#fecaca}.chroma .hl{background-color:#374151}.chroma .ln{color:#9ca3af}.chroma .k,.chroma .kc,.chroma .kd,.chroma .kn,.chroma .kp,.chroma .kr{color:#60a5fa}.chroma .kt{color:#a78bfa}.chroma .na,.chroma .nb{color:#fbbf24}.chroma .nc{color:#f87171}.chroma .no{color:#34d399}.chroma .nd{color:#f87171}.chroma .ne{color:#f87171}.chroma .nf{color:#fbbf24}.chroma .nt{color:#f87171}.chroma .l{color:#a78bfa}.chroma .dl,.chroma .ld,.chroma .s,.chroma .s2,.chroma .sa,.chroma .sb,.chroma .sc,.chroma .sd{color:#34d399}.chroma .se{color:#9ca3af}.chroma .s1,.chroma .sh,.chroma .si,.chroma .sr,.chroma .ss,.chroma .sx{color:#34d399}.chroma .il,.chroma .m,.chroma .mb,.chroma .mf,.chroma .mh,.chroma .mi,.chroma .mo{color:#a78bfa}.chroma .o,.chroma .ow{color:#93c5fd}.chroma .c,.chroma .c1,.chroma .ch,.chroma .cm,.chroma .cp,.chroma .cpf,.chroma .cs,.chroma .p{color:#9ca3af}.chroma .ge{font-style:italic}.chroma .gs{font-weight:700}</style><title>Endless Expert Levels Without Skipping in SMM2 - Part 3 - STEM</title><meta property="og:title" content="Endless Expert Levels Without Skipping in SMM2 - Part 3"><meta property="og:site_name" content="STEM"><meta property="og:url" content="https://keithyipkw.github.io/blog/no_skip_smm_part_3/"><link rel=image_src href=https://keithyipkw.github.io/blog/><meta property="og:image" content="https://keithyipkw.github.io/blog/"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="og:type" content="article"><meta property="og:locale" content="en_us"><meta property="og:description" content="In part 2, we improved the estimation of Panga's success rates of beating the various numbers of levels without skipping by utilizing the samples with a better estimator. Meanwhile, he completed more levels in his pursuit of beating 2000 levels, and it means that we have more samples for our estimation."><meta name=description content="In part 2, we improved the estimation of Panga's success rates of beating the various numbers of levels without skipping by utilizing the samples with a better estimator. Meanwhile, he completed more levels in his pursuit of beating 2000 levels, and it means that we have more samples for our estimation."><meta property="og:updated_time" content="2022-08-21T14:00:00Z"><meta property="fb:app_id" content><meta name=author content="Keith Yip"><meta property="article:author" content="https://keithyipkw.github.io/blog/"><meta property="article:published_time" content="2022-08-21T14:00:00Z"><meta property="article:modified_time" content="2022-08-21T14:00:00Z"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Endless Expert Levels Without Skipping in SMM2 - Part 3","alternativeHeadline":"In part 2, we improved the estimation of Panga's success rates of beating the various numbers of levels without skipping by utilizing the samples with a better estimator. Meanwhile, he completed more levels in his pursuit of beating 2000 levels, and it means that we have more samples for our estimation.","url":"https://keithyipkw.github.io/blog/no_skip_smm_part_3/","image":"https://keithyipkw.github.io/blog/","mainEntityOfPage":{"@type":"WebPage","@id":"https://keithyipkw.github.io/blog/no_skip_smm_part_3/"},"description":"In part 2, we improved the estimation of Panga's success rates of beating the various numbers of levels without skipping by utilizing the samples with a better estimator. Meanwhile, he completed more levels in his pursuit of beating 2000 levels, and it means that we have more samples for our estimation.","author":{"@type":"Person","name":"Keith Yip"},"publisher":{"@type":"Organization","name":"STEM","logo":{"@type":"ImageObject","url":"https://keithyipkw.github.io/blog/image/brand/icon-1-1.png"}},"datePublished":"2022-08-21T14:00:00Z","dateModified":"2022-08-21T14:00:00Z","articleBody":"\u003cp\u003eIn \u003ca href=\"https://keithyipkw.github.io/blog/no_skip_smm_part_2/\"\u003epart 2\u003c/a\u003e, we improved the estimation of Panga's success rates of beating the various numbers of levels without skipping by utilizing the samples with a better estimator. Meanwhile, he completed more levels in his pursuit of beating 2000 levels, and it means that we have more samples for our estimation.\u003c/p\u003e\n\u003ch1 id=\"new-data\"\u003eNew Data\u003c/h1\u003e\n\u003cp\u003eWith the new total of 2573 samples, far more than the previous 726 samples, the estimation will be significantly more precise. As expected, the distribution of the samples is similar to that before.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/life_change_pmf.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/life_change_pmf.png 1x,/blog/image/no_skip_smm_3/life_change_pmf_2x.png 2x\"\r\nalt=\"The overall sample distribution of Panga\u0026#39;s life changes after beating a level. Values below 0.05% are visually enhanced.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe overall sample distribution of Panga's life changes after beating a level. Values below 0.05% are visually enhanced.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/life_change_pmf_group.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/life_change_pmf_group.png 1x,/blog/image/no_skip_smm_3/life_change_pmf_group_2x.png 2x\"\r\nalt=\"The within-group sample distribution of Panga\u0026#39;s life changes after beating a level. Values below 0.05% are visually enhanced.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe within-group sample distribution of Panga's life changes after beating a level. Values below 0.05% are visually enhanced.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003ePanga's best run tragically ended by a triple-triple shell jump level (performing three triple shell jumps) and reached 1906 levels. The level required him to spend more than 99 lives to beat. Encountering such a level was virtually a guaranteed end of a run for any player. His two subsequent runs also ended similarly by two triple shell jump levels.\u003c/p\u003e\n\u003cdiv class=\"yt-container-16-9\"\u003e\r\n    \u003ciframe src=\"https://www.youtube-nocookie.com/embed/hvbGMohca94?start=1389\u0026end=1410\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\r\n\u003c/div\u003e\r\n\u003ch1 id=\"validation-of-the-assumption-in-part-1\"\u003eValidation of the Assumption in Part 1\u003c/h1\u003e\n\u003cp\u003eIn \u003ca href=\"https://keithyipkw.github.io/blog/no_skip_smm/\"\u003epart 1\u003c/a\u003e, we made the assumption\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe player performs practically the same when their number of lives is from 1 to 96 or 97 to 99.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eTo roughly check the assumption, we will compare the life change probabilities by considering the uncertainty per each starting life. As shown in the following graphs, almost all values are either very close or within random variations. The remaining rare instances are still explainable by random chance. Comparing the uncensored values across all the graphs, the results are the same.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/life_change_pdf_97.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/life_change_pdf_97.png 1x,/blog/image/no_skip_smm_3/life_change_pdf_97_2x.png 2x\"\r\nalt=\"Panga\u0026#39;s life change probabilities after beating a level for 97 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003ePanga's life change probabilities after beating a level for 97 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/life_change_pdf_98.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/life_change_pdf_98.png 1x,/blog/image/no_skip_smm_3/life_change_pdf_98_2x.png 2x\"\r\nalt=\"Panga\u0026#39;s life change probabilities after beating a level for 98 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003ePanga's life change probabilities after beating a level for 98 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/life_change_pdf_99.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/life_change_pdf_99.png 1x,/blog/image/no_skip_smm_3/life_change_pdf_99_2x.png 2x\"\r\nalt=\"Panga\u0026#39;s life change probabilities after beating a level for 99 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003ePanga's life change probabilities after beating a level for 99 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eA complete and proper examination should be a hypothesis test like an equivalence test on more important combinations of the starting lives and life changes. People, even scientists, often misinterpret the significance of overlapping probabilities and error bars\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e. I will leave the test for those who are interested. If you do, be aware of false discoveries you may encounter when checking too many combinations.\u003c/p\u003e\n\u003ch1 id=\"result\"\u003eResult\u003c/h1\u003e\n\u003cp\u003eThe sample probabilities and confidence intervals of Panga beating 1000, 2000, and 3000 levels plummet as the rare events surfaced. The sample probabilities hovered at 70% last time but become 15%, 4%, and 1% for the respective levels. The lower confidence limits are less than 3% to near impossible. The upper confidence limits drop from 91% to about 60%.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eLevels\u003c/th\u003e\n\u003cth\u003eProbability\u003c/th\u003e\n\u003cth\u003e95% CI\u003c/th\u003e\n\u003cth\u003e99% CI\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e1000\u003c/td\u003e\n\u003ctd\u003e14.9%\u003c/td\u003e\n\u003ctd\u003e[2.68%, 48.5%]\u003c/td\u003e\n\u003ctd\u003e[1.44%, 63%]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2000\u003c/td\u003e\n\u003ctd\u003e3.97%\u003c/td\u003e\n\u003ctd\u003e[0.131%, 36.9%]\u003c/td\u003e\n\u003ctd\u003e[0.0391%, 59.2%]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3000\u003c/td\u003e\n\u003ctd\u003e1.06%\u003c/td\u003e\n\u003ctd\u003e[0.00633%, 29.2%]\u003c/td\u003e\n\u003ctd\u003e[0.00104%, 55.8%]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_probabilities.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_probabilities.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_2x.png 2x\"\r\nalt=\"Probabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eProbabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_probabilities_simplified.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_probabilities_simplified.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_simplified_2x.png 2x\"\r\nalt=\"Probabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eProbabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_probability_1000.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_probability_1000.png 1x,/blog/image/no_skip_smm_3/pangas_probability_1000_2x.png 2x\"\r\nalt=\"Probability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eProbability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_cdf_1000.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_cdf_1000.png 1x,/blog/image/no_skip_smm_3/pangas_cdf_1000_2x.png 2x\"\r\nalt=\"Cumulative probability of Panga successfully beating 1000 levels.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eCumulative probability of Panga successfully beating 1000 levels.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eAs a reminder, the inference used here is frequentist. The probabilities of the confidence intervals and cumulative probabilities refer to the corresponding (hypothetical) long-run frequencies that the sampling and estimation procedure are correct. For example, a 99% confidence interval means that 99% of such confidence intervals generated by the confidence procedure cover the true success rate. Whether an interval covers the true success rate is deterministic yes or no but is unknown to us.\u003c/p\u003e\n\u003ch1 id=\"reaper-levels\"\u003eReaper Levels\u003c/h1\u003e\n\u003cp\u003eDodging run-ending levels are hard. It is like avoiding getting a one when you try throwing a dice many times. You may be able to throw 10 times, but if you keep throwing, you will eventually get a one. The exact probabilities of those happening are easy to calculate. Suppose that $ p $ is the probability of the outcome in an event, the probability of not having the outcome in $ n $ events is the complement of $ p $, raised to the power of $ n $:\u003c/p\u003e\n\r\n$$\r\nP(n) = (1 - p)^n \r\n$$\r\n\n\u003cp\u003eLet us only consider the sample probability of Panga encountering a run-ending level first for simplicity. It is 3 out of 2573 which is 0.117%. Plugging the number into the formula, we have the values shown in the following graph:\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_probabilities_avoiding_reaper.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_probabilities_avoiding_reaper.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_avoiding_reaper_2x.png 2x\"\r\nalt=\"The probabilities of Panga doging a run-ending level when playing certain number of levels.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe probabilities of Panga doging a run-ending level when playing certain number of levels.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eThis kind of level alone is enough to bring the success rate of beating 1000 levels down to 31% and 2000 levels down to 9.7%.\u003c/p\u003e\n\u003cp\u003eThe true probability of encountering a run-ending level is unknown as usual, so we should apply the formula to other possible values too. For instance, the upper 99% confidence limit of an encounter is 0.460%. It greatly lowers the success rate of beating 1000 and 2000 levels to 0.99% and 0.0099% respectively.\u003c/p\u003e\n\u003ch1 id=\"precision\"\u003ePrecision\u003c/h1\u003e\n\u003cp\u003eThe estimations sometimes can be off very much as shown in \u003ca href=\"https://keithyipkw.github.io/blog/no_skip_smm_part_2/\"\u003epart 2\u003c/a\u003e and here. The estimated Panga's success rate of beating 1000 levels was previously 61.6% but is 14.9% here. The estimated success rate is sensitive to small errors in the estimated probabilities of encountering some levels, like the reaper levels. Recalls that we calculated the estimated success rate by multiplying the state vector to the transition matrix thousands of times. A small error accumulated into a huge error in the final estimation. Randomness was the first source of the error. Discreteness in the sample space, which was the probability of encountering a level causing a certain life change, was the second source. Such a sample probability could only be one of the finitely many values regardless of random chance. It might be $ \\frac{1}{2573} $, $ \\frac{2}{2573} $, $ \\frac{3}{2573} $, or so on, but never $ \\frac{0.5}{2573} $. The resolution might not be enough.\u003c/p\u003e\n\u003cp\u003eTo illustrate the effect, we add one sample of each life change to the existing 2573 samples and calculate the corresponding rates:\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_success_rates_1000_levels_adding_1_sample.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_success_rates_1000_levels_adding_1_sample.png 1x,/blog/image/no_skip_smm_3/pangas_success_rates_1000_levels_adding_1_sample_2x.png 2x\"\r\nalt=\"Panga\u0026#39;s success rates of beating 1000 levels after adding a sample of various life changes.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003ePanga's success rates of beating 1000 levels after adding a sample of various life changes.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eThe original sample success rate is about 15%. Adding a sample with a small life change does not affect the rate much. However, when the life loss increases, the difference grows substantially. At the extreme, it drops from 15% to 10%.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_success_rates_adding_1_sample.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_success_rates_adding_1_sample.png 1x,/blog/image/no_skip_smm_3/pangas_success_rates_adding_1_sample_2x.png 2x\"\r\nalt=\"Panga\u0026#39;s success rates of beating various numbers of levels after adding a sample of various life changes in a semi-log scale. The spaces between the lines denoting the success rates increase as the level of greater life loss is more impactful to the estimations.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003ePanga's success rates of beating various numbers of levels after adding a sample of various life changes in a semi-log scale. The spaces between the lines denoting the success rates increase as the level of greater life loss is more impactful to the estimations.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eThe effect grows as the number of levels increases. At 1000 levels, the rate after adding a 99-life loss sample drops from 15% to 10%, which is one-third of 15%. At 3000 levels, it drops from 1% to 0.3%, which is two-thirds of 1%. In short, the estimations are sensitive to the discreteness and the randomness of some measurements. When everything compounds, they seriously affect the precision of our estimations.\u003c/p\u003e\n\u003cp\u003eWhat about the confidence intervals? Can they rescue us? The answer is \u0026quot;kind of\u0026quot;. They help by stating intervals instead of point estimations but not in the way we demand. There is only one basic property of a confidence interval. Its construction procedure needs to generate intervals covering the true value with the specified rate in long run. The closeness between the ends of the intervals and the true value is not a concern, although some confidence intervals handle it somewhat nicely. The confidence interval calculated by Z-score for normal distributions is an example. If precision is a concern, it is better to directly estimate the precision, use an appropriate confidence procedure, or use other intervals, e.g. \u003ca href=\"https://en.wikipedia.org/wiki/Credible_interval\"\u003eBayesian credible intervals\u003c/a\u003e. Bayesian is another popular inference besides frequentist. When a credible interval says that the probability of a value falls into the interval, it means the probability among all possible parameters. That is what people usually have in mind. Credible intervals operate on likelihoods, so they are more connected to precision.\u003c/p\u003e\n\u003cp\u003eDespite all these, bootstraps are generally quite good at reflecting precision when there are sufficient samples. They have some Bayesian properties\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e and so produce intervals approximating credible intervals with a caveat. In \u0026quot;The Bayesian Bootstrap\u0026quot;\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e, just as Rubin (1981) stated:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e... is it reasonable to use a model specification that effectively assumes all possible distinct values of X have been observed? Both the BB and the bootstrap operate under this assumption. In some cases inferences may be insensitive to this assumption but not always. (p. 133)\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eWe happened to encounter the perfect example in part 1, having no samples on the most influential non-zero parameter. However, this time we have samples for the 99-life loss. Even though we have no samples for other very large life losses, it should be fine. The distributions of the samples clearly show right-censored bell shapes. Extrapolating the trend to very large life losses indicates that the true probabilities are likely to be vanishingly small. They are different from the special 99 life-loss, which includes all even harder levels. Our new confidence interval now can reflect the precision.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/life_change_pmf_group_97.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/life_change_pmf_group_97.png 1x,/blog/image/no_skip_smm_3/life_change_pmf_group_97_2x.png 2x\"\r\nalt=\"The within-group sample distribution of Panga\u0026#39;s life changes after beating a level with a start lives less than 97 in linear scales. The distribution shows a right-censored bell shape. Encountering a level causing a huge life loss other than 99 lives should be vanishingly rare.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe within-group sample distribution of Panga's life changes after beating a level with a start lives less than 97 in linear scales. The distribution shows a right-censored bell shape. Encountering a level causing a huge life loss other than 99 lives should be vanishingly rare.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003ch1 id=\"to-infinity\"\u003eTo Infinity\u003c/h1\u003e\n\u003cp\u003eThe graph of the sample and confidence intervals of Panga's success rate of beating various levels looks suspiciously like exponential decays. Plotting it with a log scale on the y-axis reveals the long-term trend of the success rate, which is linear in a log scale.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_probabilities_simplified_log.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_probabilities_simplified_log.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_simplified_log_2x.png 2x\"\r\nalt=\"Probabilities of Panga successfully beating various numbers of levels in a log scale. The decays are exponential and so linear in log scale.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eProbabilities of Panga successfully beating various numbers of levels in a log scale. The decays are exponential and so linear in log scale.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eIt suggests the following asymptotic behaviors. Let\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$ P(k) $ be the probability of beating $ k $ levels,\u003c/li\u003e\n\u003cli\u003e$ a $, $ b $ be some constants,\u003c/li\u003e\n\u003cli\u003e$ \\lambda $ be the constant decay rate,\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eand with\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$ \\sim $ denoting \u0026quot;is asymptotically equivalent to\u0026quot;,\u003c/li\u003e\n\u003cli\u003e$ \\to $ denoting \u0026quot;tends to\u0026quot;,\u003c/li\u003e\n\u003cli\u003e$ ak+b $ being the linear relationship.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe have\u003c/p\u003e\n\r\n$$\r\n\\begin{aligned}\r\n\r\nP(k) \u0026\\sim e^{ak+b} \\\\\r\nP(k+1) \u0026\\sim \\lambda P(k) \\quad \\text{as } k \\to \\infty \\\\\r\n\r\n\\end{aligned}\r\n$$\r\n\n\u003cp\u003eThe constant decay rate comes from a deeper cause. In \u003ca href=\"https://keithyipkw.github.io/blog/no_skip_smm/\"\u003epart 1\u003c/a\u003e, we learnt that by formulating the problem as a Markov process, we could calculate $ P(k+1) $ from the state vector $ \\vec s_k $ and transition matrix $ \\mathbf T_{100\\times100} $:\u003c/p\u003e\n\r\n$$\r\n\\begin{aligned}\r\n\\vec s_k \u0026= \\begin{bmatrix}\r\nP_s(k,\\textcolor{red}{♥}=0) \u0026 P_s(k,\\textcolor{red}{♥}=1) \u0026 \\ldots \u0026 P_s(k,\\textcolor{red}{♥}=99)\r\n\\end{bmatrix} \\\\ \\\\\r\n\r\n\\mathbf T \u0026= \\begin{bmatrix}\r\n1 \u0026 0 \u0026 \\ldots \u0026 0 \\\\\r\nP_t(\\textcolor{red}{♥}=1,\\Delta\\textcolor{red}{♥}=-1) \u0026 P_t(\\textcolor{red}{♥}=1,\\Delta\\textcolor{red}{♥}=0) \u0026 \\ldots \u0026 P_t(\\textcolor{red}{♥}=1,\\Delta\\textcolor{red}{♥}=98) \\\\\r\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r\nP_t(\\textcolor{red}{♥}=99,\\Delta\\textcolor{red}{♥}=-99) \u0026 P_t(\\textcolor{red}{♥}=99,\\Delta\\textcolor{red}{♥}=-98) \u0026 \\ldots \u0026 P_t(\\textcolor{red}{♥}=99,\\Delta\\textcolor{red}{♥}=0) \\\\\r\n\\end{bmatrix} \\\\ \\\\\r\n\r\n\\vec s_{k+1} \u0026= \\vec s_k \\mathbf T \\\\ \\\\\r\n\r\nP(k) \u0026= 1 - P_s(k,\\textcolor{red}{♥}=0) \\\\\r\n\u0026= \\sum_{\\textcolor{red}{♥}=1}^{99} P_s(k,\\textcolor{red}{♥})\r\n\r\n\\end{aligned}\r\n$$\r\n\n\u003cp\u003ePartitioning the state vector gives the non-absorbing state (survival state) vector $ \\vec r $ and the transition matrix gives the corresponding transition matrix $ \\mathbf U_{99\\times99} $:\u003c/p\u003e\n\r\n$$\r\n\\begin{aligned}\r\n\r\n\\vec s_{k} \u0026= \\begin{bmatrix}\r\nP_s(k,\\textcolor{red}{♥}=0) \u0026 \\vec r_k\r\n\\end{bmatrix} \\\\\r\n\r\n\\mathbf T \u0026= \\left[ \\begin{array}{c|c}\r\n1 \u0026 \\begin{matrix}\r\n    0 \u0026 \\ldots \u0026 0\r\n    \\end{matrix} \\\\\r\n\\hline\r\n    \\begin{matrix}\r\n    P_t(\\textcolor{red}{♥}=1,\\Delta\\textcolor{red}{♥}=-1) \\\\\r\n    \\vdots \\\\\r\n    P_t(\\textcolor{red}{♥}=99,\\Delta\\textcolor{red}{♥}=-99)\r\n    \\end{matrix} \u0026 \\Large \\mathbf U\r\n\\end{array} \\right]\r\n\r\n\\end{aligned}\r\n$$\r\n\n\u003cp\u003eThen we have:\u003c/p\u003e\n\r\n$$\r\n\\begin{align}\r\n\r\nP(k) \u0026= \\sum_{i=1}^{99} r_{k,i} \\notag \\\\\r\n\\vec r_{k+1} \u0026= \\vec r_k \\mathbf U \\label{eq1}\r\n\r\n\\end{align}\r\n$$\r\n\n\u003cp\u003eThe asymptotic process that a state is similar to its previous state causes exponential decay of the success rate:\u003c/p\u003e\n\r\n$$\r\n\\begin{aligned}\r\n\r\n\\vec r_{k+1} \u0026\\sim \\lambda \\vec r_k \\quad \\text{as } k \\to \\infty \\\\\r\nP(k+1) \u0026= \\sum_{i=1}^{99} r_{k+1,i} \\\\\r\n\u0026\\sim \\sum_{i=1}^{99} \\lambda r_{k,i} \\\\\r\n\u0026= \\lambda P(k)\r\n\r\n\\end{aligned}\r\n$$\r\n\n\u003cp\u003eA simple way to calculate the decay rate is to iterate equation $ \\ref{eq1} $ until the value converges. The decay rate quickly converges to 99.87%.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_sample_success_rate_decay.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_sample_success_rate_decay.png 1x,/blog/image/no_skip_smm_3/pangas_sample_success_rate_decay_2x.png 2x\"\r\nalt=\"The decay rate of Panga\u0026#39;s sample success rate in each iteration. It settles down at about 600 levels.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe decay rate of Panga's sample success rate in each iteration. It settles down at about 600 levels.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003cp\u003eThere is another interesting but slightly more complicated way to calculate the decay rate. $ \\vec r_k $ are similar to each other and differ by a scale. If we normalize it, take the limit, and substitute it into $ \\ref {eq1} $, we have a new equation:\u003c/p\u003e\n\r\n$$\r\n\r\n\\vec r \\mathbf U = \\lambda \\vec r\r\n\r\n$$\r\n\n\u003cp\u003ewhere\u003c/p\u003e\n\r\n$$\r\n\r\n\\vec r = \\lim_{k \\to \\infty}\\frac{\\vec r_{k}}{\\sum_{i=1}^{99} r_{k,i}}\r\n\r\n$$\r\n\n\u003cp\u003e$ \\vec r $ is an \u003ca href=\"https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors\"\u003eeigenvector\u003c/a\u003e of $ \\mathbf U $ and $ \\lambda $ is the corresponding eigenvalue. The equation means that when the vector multiplies the matrix, the result is the same as it multiplying with a constant. Such an equation is so common in science and engineering that most linear algebra software provides direct functionalities to solve it. However, the complication is after that. There are as many pairs of eigenvector and eigenvalue as the dimension of the matrix, which is 99 pairs here. For Panga's transition matrix, there is one sensible pair that\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ehas a real eigenvector,\u003c/li\u003e\n\u003cli\u003eall elements in the eigenvector and the eigenvalue have the same sign.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHere, we only need to pick the pair of eigenvector and eigenvalue with all the elements being positive and the eigenvalue being less than one after normalization. Either way gives us the same solution.\u003c/p\u003e\n\r\n\r\n\u003cfigure\u003e\r\n\u003cimg\r\nclass=\"mx-auto leading-none\"\r\nsrc=\"/blog/image/no_skip_smm_3/pangas_lives_limit_distribution.png\"\r\nsrcset=\"/blog/image/no_skip_smm_3/pangas_lives_limit_distribution.png 1x,/blog/image/no_skip_smm_3/pangas_lives_limit_distribution_2x.png 2x\"\r\nalt=\"The normalized limiting distribution of Panga\u0026#39;s lives $ \\vec r $ after beating a level. Having a healthy amount of lives was one of his advantages.\"\u003e\r\n\u003cfigcaption class=\"text-center text-raven-500\"\u003e\r\n\u003cp\u003eThe normalized limiting distribution of Panga's lives $ \\vec r $ after beating a level. Having a healthy amount of lives was one of his advantages.\u003c/p\u003e\r\n\u003c/figcaption\u003e\r\n\u003c/figure\u003e\r\n\n\u003ch1 id=\"conclsuion\"\u003eConclsuion\u003c/h1\u003e\n\u003cp\u003eWith the new samples, we could better validate the assumption we made before that the player performs practically the same regardless of their starting lives and improve the estimation of Panga's success rate. Our analysis revealed the key to performing well in the no-skip endless challenge other than being generally good at the game. Because Nintendo's level rating system is imprecise for freshly uploaded levels made by and played by other top players, you must prepare for those levels too. We also experienced a perfect example of the limitation of bootstraps. They did not give confidence intervals that had the Bayesian properties and fell back to the minimal frequentist interpretation when there were insufficient samples for sensitive parameters. Perhaps in the future, we will try a Bayesian inference.\u003c/p\u003e\n\u003csection class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n\u003cp\u003eKrzywinski, M., Altman, N. Error bars. Nat Methods10, 921–922 (2013). https://doi.org/10.1038/nmeth.2659 \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n\u003cp\u003eDonald B. Rubin.  \u0026quot;The Bayesian Bootstrap.\u0026quot; Ann. Statist. 9 (1) 130 - 134, January, 1981. https://doi.org/10.1214/aos/1176345338 \u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\" role=\"doc-endnote\"\u003e\n\u003cp\u003eTrevor Hastie, Robert Tibshirani, Jerome Friedman. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Second Edition, February 2009. \u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/section\u003e"}</script><link rel=preload as=script href="/blog/bundle.js?v=1661093204"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://stats.g.doubleclick.net><link rel=preconnect href=https://www.googleadservices.com><link rel=preload as=script href="https://www.googletagmanager.com/gtag/js?id=G-5Y5GJS2SYG"><script src="https://www.googletagmanager.com/gtag/js?id=G-5Y5GJS2SYG"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('consent','default',{'ad_storage':'denied','analytics_storage':'denied'});gtag('js',new Date());gtag('config','G-5Y5GJS2SYG');</script><script>MathJax={loader:{load:['[tex]/mathtools']},tex:{inlineMath:[['$','$']],packages:{'[+]':['mathtools']},tags:'ams'}};</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><header id=nav class=header><div class="ax-l-i max-w-7xl"><div class=ax-logo><a class=block href=/blog/ title=STEM><img src=/blog/image/brand/logo.png alt=STEM></a></div><div class=ax-user></div></div></header><main><div class=default-single><div class="ax-title ax-l-o"><div class="ax-l-i max-w-7xl"><h1 class="post-title font-content-title font-semibold leading-tight tracking-default text-40">Endless Expert Levels Without Skipping in SMM2 - Part 3</h1><div class="ax-meta flex items-center mt-5"><div class="flex-grow min-w-0"><div class="flex items-center"><div class="flex-shrink-0 leading-tight font-content-sans"><div class="block text-sm">Keith Yip</div><time class="text-sm text-raven-500" datetime=2022-08-21T14:00:00Z>Aug 21, 2022 10:00PM</time></div></div></div></div></div></div><div class="flex flex-wrap justify-center"><a class="rounded font-content-sans font-semibold text-raven-700 bg-raven-100 hover:bg-raven-200 py-2 px-4 m-2" href=https://keithyipkw.github.io/blog/tags/statistics/>Statistics</a></div><div class="ax-content ax-l-o"><div class="ax-l-i max-w-7xl"><article class=cdata><p>In <a href=https://keithyipkw.github.io/blog/no_skip_smm_part_2/>part 2</a>, we improved the estimation of Panga's success rates of beating the various numbers of levels without skipping by utilizing the samples with a better estimator. Meanwhile, he completed more levels in his pursuit of beating 2000 levels, and it means that we have more samples for our estimation.</p><h1 id=new-data>New Data</h1><p>With the new total of 2573 samples, far more than the previous 726 samples, the estimation will be significantly more precise. As expected, the distribution of the samples is similar to that before.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/life_change_pmf.png srcset="/blog/image/no_skip_smm_3/life_change_pmf.png 1x,/blog/image/no_skip_smm_3/life_change_pmf_2x.png 2x" alt="The overall sample distribution of Panga's life changes after beating a level. Values below 0.05% are visually enhanced."><figcaption class="text-center text-raven-500"><p>The overall sample distribution of Panga's life changes after beating a level. Values below 0.05% are visually enhanced.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/life_change_pmf_group.png srcset="/blog/image/no_skip_smm_3/life_change_pmf_group.png 1x,/blog/image/no_skip_smm_3/life_change_pmf_group_2x.png 2x" alt="The within-group sample distribution of Panga's life changes after beating a level. Values below 0.05% are visually enhanced."><figcaption class="text-center text-raven-500"><p>The within-group sample distribution of Panga's life changes after beating a level. Values below 0.05% are visually enhanced.</p></figcaption></figure><p>Panga's best run tragically ended by a triple-triple shell jump level (performing three triple shell jumps) and reached 1906 levels. The level required him to spend more than 99 lives to beat. Encountering such a level was virtually a guaranteed end of a run for any player. His two subsequent runs also ended similarly by two triple shell jump levels.</p><div class=yt-container-16-9><iframe src="https://www.youtube-nocookie.com/embed/hvbGMohca94?start=1389&end=1410" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><h1 id=validation-of-the-assumption-in-part-1>Validation of the Assumption in Part 1</h1><p>In <a href=https://keithyipkw.github.io/blog/no_skip_smm/>part 1</a>, we made the assumption</p><blockquote><p>The player performs practically the same when their number of lives is from 1 to 96 or 97 to 99.</p></blockquote><p>To roughly check the assumption, we will compare the life change probabilities by considering the uncertainty per each starting life. As shown in the following graphs, almost all values are either very close or within random variations. The remaining rare instances are still explainable by random chance. Comparing the uncensored values across all the graphs, the results are the same.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/life_change_pdf_97.png srcset="/blog/image/no_skip_smm_3/life_change_pdf_97.png 1x,/blog/image/no_skip_smm_3/life_change_pdf_97_2x.png 2x" alt="Panga's life change probabilities after beating a level for 97 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion."><figcaption class="text-center text-raven-500"><p>Panga's life change probabilities after beating a level for 97 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/life_change_pdf_98.png srcset="/blog/image/no_skip_smm_3/life_change_pdf_98.png 1x,/blog/image/no_skip_smm_3/life_change_pdf_98_2x.png 2x" alt="Panga's life change probabilities after beating a level for 98 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion."><figcaption class="text-center text-raven-500"><p>Panga's life change probabilities after beating a level for 98 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/life_change_pdf_99.png srcset="/blog/image/no_skip_smm_3/life_change_pdf_99.png 1x,/blog/image/no_skip_smm_3/life_change_pdf_99_2x.png 2x" alt="Panga's life change probabilities after beating a level for 99 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion."><figcaption class="text-center text-raven-500"><p>Panga's life change probabilities after beating a level for 99 starting lives or those below. Each probability density function is calculated independently by using the binomial proportion.</p></figcaption></figure><p>A complete and proper examination should be a hypothesis test like an equivalence test on more important combinations of the starting lives and life changes. People, even scientists, often misinterpret the significance of overlapping probabilities and error bars<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. I will leave the test for those who are interested. If you do, be aware of false discoveries you may encounter when checking too many combinations.</p><h1 id=result>Result</h1><p>The sample probabilities and confidence intervals of Panga beating 1000, 2000, and 3000 levels plummet as the rare events surfaced. The sample probabilities hovered at 70% last time but become 15%, 4%, and 1% for the respective levels. The lower confidence limits are less than 3% to near impossible. The upper confidence limits drop from 91% to about 60%.</p><table><thead><tr><th>Levels</th><th>Probability</th><th>95% CI</th><th>99% CI</th></tr></thead><tbody><tr><td>1000</td><td>14.9%</td><td>[2.68%, 48.5%]</td><td>[1.44%, 63%]</td></tr><tr><td>2000</td><td>3.97%</td><td>[0.131%, 36.9%]</td><td>[0.0391%, 59.2%]</td></tr><tr><td>3000</td><td>1.06%</td><td>[0.00633%, 29.2%]</td><td>[0.00104%, 55.8%]</td></tr></tbody></table><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_probabilities.png srcset="/blog/image/no_skip_smm_3/pangas_probabilities.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_2x.png 2x" alt="Probabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities."><figcaption class="text-center text-raven-500"><p>Probabilities of Panga successfully beating various numbers of levels. The darkest color denotes the medians of the probabilities.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_probabilities_simplified.png srcset="/blog/image/no_skip_smm_3/pangas_probabilities_simplified.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_simplified_2x.png 2x" alt="Probabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown."><figcaption class="text-center text-raven-500"><p>Probabilities of Panga successfully beating various numbers of levels. Only 95% and 99% confidence intervals are shown.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_probability_1000.png srcset="/blog/image/no_skip_smm_3/pangas_probability_1000.png 1x,/blog/image/no_skip_smm_3/pangas_probability_1000_2x.png 2x" alt="Probability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward."><figcaption class="text-center text-raven-500"><p>Probability of Panga successfully beating 1000 levels. It is a vertical slice of the level 1000 of the previous two graphs, and like a graph of the cumulative probability but with the 0% - 50% part being flipped upward.</p></figcaption></figure><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_cdf_1000.png srcset="/blog/image/no_skip_smm_3/pangas_cdf_1000.png 1x,/blog/image/no_skip_smm_3/pangas_cdf_1000_2x.png 2x" alt="Cumulative probability of Panga successfully beating 1000 levels."><figcaption class="text-center text-raven-500"><p>Cumulative probability of Panga successfully beating 1000 levels.</p></figcaption></figure><p>As a reminder, the inference used here is frequentist. The probabilities of the confidence intervals and cumulative probabilities refer to the corresponding (hypothetical) long-run frequencies that the sampling and estimation procedure are correct. For example, a 99% confidence interval means that 99% of such confidence intervals generated by the confidence procedure cover the true success rate. Whether an interval covers the true success rate is deterministic yes or no but is unknown to us.</p><h1 id=reaper-levels>Reaper Levels</h1><p>Dodging run-ending levels are hard. It is like avoiding getting a one when you try throwing a dice many times. You may be able to throw 10 times, but if you keep throwing, you will eventually get a one. The exact probabilities of those happening are easy to calculate. Suppose that $ p $ is the probability of the outcome in an event, the probability of not having the outcome in $ n $ events is the complement of $ p $, raised to the power of $ n $:</p>$$
P(n) = (1 - p)^n
$$<p>Let us only consider the sample probability of Panga encountering a run-ending level first for simplicity. It is 3 out of 2573 which is 0.117%. Plugging the number into the formula, we have the values shown in the following graph:</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_probabilities_avoiding_reaper.png srcset="/blog/image/no_skip_smm_3/pangas_probabilities_avoiding_reaper.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_avoiding_reaper_2x.png 2x" alt="The probabilities of Panga doging a run-ending level when playing certain number of levels."><figcaption class="text-center text-raven-500"><p>The probabilities of Panga doging a run-ending level when playing certain number of levels.</p></figcaption></figure><p>This kind of level alone is enough to bring the success rate of beating 1000 levels down to 31% and 2000 levels down to 9.7%.</p><p>The true probability of encountering a run-ending level is unknown as usual, so we should apply the formula to other possible values too. For instance, the upper 99% confidence limit of an encounter is 0.460%. It greatly lowers the success rate of beating 1000 and 2000 levels to 0.99% and 0.0099% respectively.</p><h1 id=precision>Precision</h1><p>The estimations sometimes can be off very much as shown in <a href=https://keithyipkw.github.io/blog/no_skip_smm_part_2/>part 2</a> and here. The estimated Panga's success rate of beating 1000 levels was previously 61.6% but is 14.9% here. The estimated success rate is sensitive to small errors in the estimated probabilities of encountering some levels, like the reaper levels. Recalls that we calculated the estimated success rate by multiplying the state vector to the transition matrix thousands of times. A small error accumulated into a huge error in the final estimation. Randomness was the first source of the error. Discreteness in the sample space, which was the probability of encountering a level causing a certain life change, was the second source. Such a sample probability could only be one of the finitely many values regardless of random chance. It might be $ \frac{1}{2573} $, $ \frac{2}{2573} $, $ \frac{3}{2573} $, or so on, but never $ \frac{0.5}{2573} $. The resolution might not be enough.</p><p>To illustrate the effect, we add one sample of each life change to the existing 2573 samples and calculate the corresponding rates:</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_success_rates_1000_levels_adding_1_sample.png srcset="/blog/image/no_skip_smm_3/pangas_success_rates_1000_levels_adding_1_sample.png 1x,/blog/image/no_skip_smm_3/pangas_success_rates_1000_levels_adding_1_sample_2x.png 2x" alt="Panga's success rates of beating 1000 levels after adding a sample of various life changes."><figcaption class="text-center text-raven-500"><p>Panga's success rates of beating 1000 levels after adding a sample of various life changes.</p></figcaption></figure><p>The original sample success rate is about 15%. Adding a sample with a small life change does not affect the rate much. However, when the life loss increases, the difference grows substantially. At the extreme, it drops from 15% to 10%.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_success_rates_adding_1_sample.png srcset="/blog/image/no_skip_smm_3/pangas_success_rates_adding_1_sample.png 1x,/blog/image/no_skip_smm_3/pangas_success_rates_adding_1_sample_2x.png 2x" alt="Panga's success rates of beating various numbers of levels after adding a sample of various life changes in a semi-log scale. The spaces between the lines denoting the success rates increase as the level of greater life loss is more impactful to the estimations."><figcaption class="text-center text-raven-500"><p>Panga's success rates of beating various numbers of levels after adding a sample of various life changes in a semi-log scale. The spaces between the lines denoting the success rates increase as the level of greater life loss is more impactful to the estimations.</p></figcaption></figure><p>The effect grows as the number of levels increases. At 1000 levels, the rate after adding a 99-life loss sample drops from 15% to 10%, which is one-third of 15%. At 3000 levels, it drops from 1% to 0.3%, which is two-thirds of 1%. In short, the estimations are sensitive to the discreteness and the randomness of some measurements. When everything compounds, they seriously affect the precision of our estimations.</p><p>What about the confidence intervals? Can they rescue us? The answer is "kind of". They help by stating intervals instead of point estimations but not in the way we demand. There is only one basic property of a confidence interval. Its construction procedure needs to generate intervals covering the true value with the specified rate in long run. The closeness between the ends of the intervals and the true value is not a concern, although some confidence intervals handle it somewhat nicely. The confidence interval calculated by Z-score for normal distributions is an example. If precision is a concern, it is better to directly estimate the precision, use an appropriate confidence procedure, or use other intervals, e.g. <a href=https://en.wikipedia.org/wiki/Credible_interval>Bayesian credible intervals</a>. Bayesian is another popular inference besides frequentist. When a credible interval says that the probability of a value falls into the interval, it means the probability among all possible parameters. That is what people usually have in mind. Credible intervals operate on likelihoods, so they are more connected to precision.</p><p>Despite all these, bootstraps are generally quite good at reflecting precision when there are sufficient samples. They have some Bayesian properties<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> and so produce intervals approximating credible intervals with a caveat. In "The Bayesian Bootstrap"<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, just as Rubin (1981) stated:</p><blockquote><p>... is it reasonable to use a model specification that effectively assumes all possible distinct values of X have been observed? Both the BB and the bootstrap operate under this assumption. In some cases inferences may be insensitive to this assumption but not always. (p. 133)</p></blockquote><p>We happened to encounter the perfect example in part 1, having no samples on the most influential non-zero parameter. However, this time we have samples for the 99-life loss. Even though we have no samples for other very large life losses, it should be fine. The distributions of the samples clearly show right-censored bell shapes. Extrapolating the trend to very large life losses indicates that the true probabilities are likely to be vanishingly small. They are different from the special 99 life-loss, which includes all even harder levels. Our new confidence interval now can reflect the precision.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/life_change_pmf_group_97.png srcset="/blog/image/no_skip_smm_3/life_change_pmf_group_97.png 1x,/blog/image/no_skip_smm_3/life_change_pmf_group_97_2x.png 2x" alt="The within-group sample distribution of Panga's life changes after beating a level with a start lives less than 97 in linear scales. The distribution shows a right-censored bell shape. Encountering a level causing a huge life loss other than 99 lives should be vanishingly rare."><figcaption class="text-center text-raven-500"><p>The within-group sample distribution of Panga's life changes after beating a level with a start lives less than 97 in linear scales. The distribution shows a right-censored bell shape. Encountering a level causing a huge life loss other than 99 lives should be vanishingly rare.</p></figcaption></figure><h1 id=to-infinity>To Infinity</h1><p>The graph of the sample and confidence intervals of Panga's success rate of beating various levels looks suspiciously like exponential decays. Plotting it with a log scale on the y-axis reveals the long-term trend of the success rate, which is linear in a log scale.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_probabilities_simplified_log.png srcset="/blog/image/no_skip_smm_3/pangas_probabilities_simplified_log.png 1x,/blog/image/no_skip_smm_3/pangas_probabilities_simplified_log_2x.png 2x" alt="Probabilities of Panga successfully beating various numbers of levels in a log scale. The decays are exponential and so linear in log scale."><figcaption class="text-center text-raven-500"><p>Probabilities of Panga successfully beating various numbers of levels in a log scale. The decays are exponential and so linear in log scale.</p></figcaption></figure><p>It suggests the following asymptotic behaviors. Let</p><ul><li>$ P(k) $ be the probability of beating $ k $ levels,</li><li>$ a $, $ b $ be some constants,</li><li>$ \lambda $ be the constant decay rate,</li></ul><p>and with</p><ul><li>$ \sim $ denoting "is asymptotically equivalent to",</li><li>$ \to $ denoting "tends to",</li><li>$ ak+b $ being the linear relationship.</li></ul><p>We have</p>$$
\begin{aligned}
P(k) &\sim e^{ak+b} \\
P(k+1) &\sim \lambda P(k) \quad \text{as } k \to \infty \\
\end{aligned}
$$<p>The constant decay rate comes from a deeper cause. In <a href=https://keithyipkw.github.io/blog/no_skip_smm/>part 1</a>, we learnt that by formulating the problem as a Markov process, we could calculate $ P(k+1) $ from the state vector $ \vec s_k $ and transition matrix $ \mathbf T_{100\times100} $:</p>$$
\begin{aligned}
\vec s_k &= \begin{bmatrix}
P_s(k,\textcolor{red}{♥}=0) & P_s(k,\textcolor{red}{♥}=1) & \ldots & P_s(k,\textcolor{red}{♥}=99)
\end{bmatrix} \\ \\
\mathbf T &= \begin{bmatrix}
1 & 0 & \ldots & 0 \\
P_t(\textcolor{red}{♥}=1,\Delta\textcolor{red}{♥}=-1) & P_t(\textcolor{red}{♥}=1,\Delta\textcolor{red}{♥}=0) & \ldots & P_t(\textcolor{red}{♥}=1,\Delta\textcolor{red}{♥}=98) \\
\vdots & \vdots & \ddots & \vdots \\
P_t(\textcolor{red}{♥}=99,\Delta\textcolor{red}{♥}=-99) & P_t(\textcolor{red}{♥}=99,\Delta\textcolor{red}{♥}=-98) & \ldots & P_t(\textcolor{red}{♥}=99,\Delta\textcolor{red}{♥}=0) \\
\end{bmatrix} \\ \\
\vec s_{k+1} &= \vec s_k \mathbf T \\ \\

P(k) &= 1 - P_s(k,\textcolor{red}{♥}=0) \\
&= \sum_{\textcolor{red}{♥}=1}^{99} P_s(k,\textcolor{red}{♥})
\end{aligned}
$$<p>Partitioning the state vector gives the non-absorbing state (survival state) vector $ \vec r $ and the transition matrix gives the corresponding transition matrix $ \mathbf U_{99\times99} $:</p>$$
\begin{aligned}
\vec s_{k} &= \begin{bmatrix}
P_s(k,\textcolor{red}{♥}=0) & \vec r_k
\end{bmatrix} \\

\mathbf T &= \left[ \begin{array}{c|c}
1 & \begin{matrix}
0 & \ldots & 0
    \end{matrix} \\
\hline
\begin{matrix}
P_t(\textcolor{red}{♥}=1,\Delta\textcolor{red}{♥}=-1) \\
\vdots \\
P_t(\textcolor{red}{♥}=99,\Delta\textcolor{red}{♥}=-99)
\end{matrix} & \Large \mathbf U
\end{array} \right]
\end{aligned}
$$<p>Then we have:</p>$$
\begin{align}
P(k) &= \sum_{i=1}^{99} r_{k,i} \notag \\
\vec r_{k+1} &= \vec r_k \mathbf U \label{eq1}
\end{align}
$$<p>The asymptotic process that a state is similar to its previous state causes exponential decay of the success rate:</p>$$
\begin{aligned}
\vec r_{k+1} &\sim \lambda \vec r_k \quad \text{as } k \to \infty \\
P(k+1) &= \sum_{i=1}^{99} r_{k+1,i} \\
&\sim \sum_{i=1}^{99} \lambda r_{k,i} \\
&= \lambda P(k)

\end{aligned}
$$<p>A simple way to calculate the decay rate is to iterate equation $ \ref{eq1} $ until the value converges. The decay rate quickly converges to 99.87%.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_sample_success_rate_decay.png srcset="/blog/image/no_skip_smm_3/pangas_sample_success_rate_decay.png 1x,/blog/image/no_skip_smm_3/pangas_sample_success_rate_decay_2x.png 2x" alt="The decay rate of Panga's sample success rate in each iteration. It settles down at about 600 levels."><figcaption class="text-center text-raven-500"><p>The decay rate of Panga's sample success rate in each iteration. It settles down at about 600 levels.</p></figcaption></figure><p>There is another interesting but slightly more complicated way to calculate the decay rate. $ \vec r_k $ are similar to each other and differ by a scale. If we normalize it, take the limit, and substitute it into $ \ref {eq1} $, we have a new equation:</p>$$
\vec r \mathbf U = \lambda \vec r
$$<p>where</p>$$
\vec r = \lim_{k \to \infty}\frac{\vec r_{k}}{\sum_{i=1}^{99} r_{k,i}}
$$<p>$ \vec r $ is an <a href=https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors>eigenvector</a> of $ \mathbf U $ and $ \lambda $ is the corresponding eigenvalue. The equation means that when the vector multiplies the matrix, the result is the same as it multiplying with a constant. Such an equation is so common in science and engineering that most linear algebra software provides direct functionalities to solve it. However, the complication is after that. There are as many pairs of eigenvector and eigenvalue as the dimension of the matrix, which is 99 pairs here. For Panga's transition matrix, there is one sensible pair that</p><ul><li>has a real eigenvector,</li><li>all elements in the eigenvector and the eigenvalue have the same sign.</li></ul><p>Here, we only need to pick the pair of eigenvector and eigenvalue with all the elements being positive and the eigenvalue being less than one after normalization. Either way gives us the same solution.</p><figure><img class="mx-auto leading-none" src=/blog/image/no_skip_smm_3/pangas_lives_limit_distribution.png srcset="/blog/image/no_skip_smm_3/pangas_lives_limit_distribution.png 1x,/blog/image/no_skip_smm_3/pangas_lives_limit_distribution_2x.png 2x" alt="The normalized limiting distribution of Panga's lives $ \vec r $ after beating a level. Having a healthy amount of lives was one of his advantages."><figcaption class="text-center text-raven-500"><p>The normalized limiting distribution of Panga's lives $ \vec r $ after beating a level. Having a healthy amount of lives was one of his advantages.</p></figcaption></figure><h1 id=conclsuion>Conclsuion</h1><p>With the new samples, we could better validate the assumption we made before that the player performs practically the same regardless of their starting lives and improve the estimation of Panga's success rate. Our analysis revealed the key to performing well in the no-skip endless challenge other than being generally good at the game. Because Nintendo's level rating system is imprecise for freshly uploaded levels made by and played by other top players, you must prepare for those levels too. We also experienced a perfect example of the limitation of bootstraps. They did not give confidence intervals that had the Bayesian properties and fell back to the minimal frequentist interpretation when there were insufficient samples for sensitive parameters. Perhaps in the future, we will try a Bayesian inference.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Krzywinski, M., Altman, N. Error bars. Nat Methods10, 921–922 (2013). https://doi.org/10.1038/nmeth.2659 <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>Donald B. Rubin. "The Bayesian Bootstrap." Ann. Statist. 9 (1) 130 - 134, January, 1981. https://doi.org/10.1214/aos/1176345338 <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>Trevor Hastie, Robert Tibshirani, Jerome Friedman. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Second Edition, February 2009. <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></article></div></div></div></main><footer class=footer><div class="ax-l-i max-w-6xl"><nav class="flex items-center justify-center"><a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href=/blog/blog/about/>About</a>
<a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href=/blog/blog/copyright/>Copyright</a></nav><div class="footer-copyright text-sm text-center text-gray-400 mt-4">&#169; 2022 STEM</div><div class="text-sm sm:text-xs text-center text-gray-400 mt-2">Powered by <a href="https://www.axiomtheme.com/?utm_source=theme-footer&utm_medium=website&utm_campaign=referral">Axiom</a></div></div></footer><script src="/blog/bundle.js?v=1661093204"></script></body></html>